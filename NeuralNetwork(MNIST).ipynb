{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 754,
   "id": "5ab0fb5f-1b2a-48fc-a48a-ebae2ebb083b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from sklearn.datasets import fetch_openml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 756,
   "id": "a3a52c44-c0aa-4565-a0a4-9d127ee4e205",
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y=fetch_openml('mnist_784',version=1,return_X_y=True,as_frame=False)     # Original version , returns x ,y , not as dataframe but a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 757,
   "id": "2c26ff0a-5091-450d-9a31-f0c96c479f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=x/255.0                                                                  #I will get values bw 0 and 1 as image pixel intensities are from 0-255\n",
    "y=y.astype(int)                                                            # no need of float values in true labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 758,
   "id": "99dc6911-eb97-404b-a667-987e5e20d133",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(y,classes=10):           \n",
    "    return np.eye(classes)[y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 759,
   "id": "4770f8bf-818c-44eb-a271-56c35f952c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=one_hot_encoding(y)                                                      #one hot encoding the labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 760,
   "id": "f1a3dad8-3c47-4684-9ed3-d9772834fb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,X_cv=X[:50000],X[60000:],X[50000:60000]                     # We have 70k images dividing them in test train cv splits\n",
    "Y_train,Y_test,Y_cv=Y[:50000],Y[60000:],Y[50000:60000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 761,
   "id": "297565c9-3e31-4c37-8460-72e4370af311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 784) (10000, 784) (10000, 784) (50000, 10) (10000, 10) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape,X_test.shape,X_cv.shape,Y_train.shape,Y_test.shape,Y_cv.shape)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 762,
   "id": "90fd8d8d-fb9a-4e15-a20c-088f3fce578c",
   "metadata": {},
   "outputs": [],
   "source": [
    "w1=np.random.randn(784,256)* np.sqrt(2/784)                                 # Keeping neural net deep for efficiency , initializing random weights\n",
    "b1=np.zeros((1,256))\n",
    "w2=np.random.randn(256,128)*np.sqrt(2/256)\n",
    "b2=np.zeros((1,128))\n",
    "w3=np.random.randn(128,64)*np.sqrt(2/128)\n",
    "b3=np.zeros((1,64))\n",
    "w4=np.random.randn(64,10)*np.sqrt(2/64)\n",
    "b4=np.zeros((1,10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 763,
   "id": "7b4eccbb-57b7-44e0-8081-ba1ef2610184",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(X,w1,b1,w2,b2,w3,b3,w4,b4):                        # froward propagation \n",
    "    Z1=X @ w1 + b1\n",
    "    A1=relu(Z1)\n",
    "    Z2=A1 @ w2 + b2\n",
    "    A2=relu(Z2)\n",
    "    Z3=A2 @ w3 + b3\n",
    "    A3=relu(Z3)\n",
    "    Z4=A3 @ w4 + b4\n",
    "    A4=softmax(Z4)\n",
    "    return Z1,Z2,Z3,Z4,A1,A2,A3,A4                                          # will store in cache then I'll use them for backprop \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 764,
   "id": "df152557-82ae-4c72-89d5-9d328c8d27e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(Z):                                   \n",
    "    return np.maximum(0,Z)\n",
    "def relu_derivative(Z):\n",
    "    return (Z>0).astype(float)\n",
    "def softmax(Z):\n",
    "    exp_z=np.exp(Z-np.max(Z,axis=1,keepdims=True))                         # Normalizing by substracting Z values else exponent will be large nd gradient descent will be slower\n",
    "    return exp_z/np.sum(exp_z,axis=1,keepdims=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 765,
   "id": "7fd73087-0155-4e90-9971-7c8c1e485d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_function(ytrue,ypred):\n",
    "    m = ytrue.shape[0]                                                      #y=[50000,10]  extracting m=50000\n",
    "    small_value = 1e-12                                                     # log 0 is undefined (make descent slow or might even diverge)\n",
    "    ypred_new = np.clip(ypred,small_value,1.-small_value)\n",
    "    loss= -np.sum(ytrue*np.log(ypred_new))\n",
    "    cost= loss/m\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 766,
   "id": "a2a1cb9f-ed69-45d6-aa2f-09c68241ee68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_propagation(X,Y,Z1,Z2,Z3,Z4,A1,A2,A3,A4,w1,b1,w2,b2,w3,b3,w4,b4):\n",
    "    m=X.shape[0]\n",
    "    dZ4= A4-Y\n",
    "    dw4=(1/m)*np.dot(A3.T,dZ4)\n",
    "    db4=(1/m)*np.sum(dZ4,axis=0,keepdims=True)\n",
    "    dA3=np.dot(dZ4,w4.T)\n",
    "\n",
    "    dZ3=dA3*relu_derivative(Z3)\n",
    "    dw3=(1/m)*np.dot(A2.T,dZ3)\n",
    "    db3=(1/m)*np.sum(dZ3,axis=0,keepdims=True)\n",
    "    dA2=np.dot(dZ3,w3.T)\n",
    "\n",
    "    dZ2=dA2*relu_derivative(Z2)                                               #chain rule\n",
    "    dw2=(1/m)*np.dot(A1.T,dZ2)\n",
    "    db2=(1/m)*np.sum(dZ2,axis=0,keepdims=True)\n",
    "    dA1=np.dot(dZ2,w2.T)\n",
    "\n",
    "    dZ1=dA1*relu_derivative(Z1)\n",
    "    dw1=(1/m)*np.dot(X.T,dZ1)\n",
    "    db1=(1/m)*np.sum(dZ1,axis=0,keepdims=True)\n",
    "\n",
    "    return dw1,dw2,dw3,dw4,db1,db2,db3,db4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 767,
   "id": "7f45a3da-9815-48cb-aab9-bf08f520e102",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training looooop :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 768,
   "id": "d15e0010-7859-4cb9-96fc-d7372b588161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150 | Cost: 2.393016\n",
      "Epoch 2/150 | Cost: 2.326879\n",
      "Epoch 3/150 | Cost: 2.280431\n",
      "Epoch 4/150 | Cost: 2.242515\n",
      "Epoch 5/150 | Cost: 2.208875\n",
      "Epoch 6/150 | Cost: 2.177541\n",
      "Epoch 7/150 | Cost: 2.147525\n",
      "Epoch 8/150 | Cost: 2.118264\n",
      "Epoch 9/150 | Cost: 2.089381\n",
      "Epoch 10/150 | Cost: 2.060589\n",
      "Epoch 11/150 | Cost: 2.031595\n",
      "Epoch 12/150 | Cost: 2.002252\n",
      "Epoch 13/150 | Cost: 1.972336\n",
      "Epoch 14/150 | Cost: 1.941738\n",
      "Epoch 15/150 | Cost: 1.910426\n",
      "Epoch 16/150 | Cost: 1.878313\n",
      "Epoch 17/150 | Cost: 1.845394\n",
      "Epoch 18/150 | Cost: 1.811683\n",
      "Epoch 19/150 | Cost: 1.777247\n",
      "Epoch 20/150 | Cost: 1.742135\n",
      "Epoch 21/150 | Cost: 1.706396\n",
      "Epoch 22/150 | Cost: 1.670127\n",
      "Epoch 23/150 | Cost: 1.633461\n",
      "Epoch 24/150 | Cost: 1.596495\n",
      "Epoch 25/150 | Cost: 1.559406\n",
      "Epoch 26/150 | Cost: 1.522312\n",
      "Epoch 27/150 | Cost: 1.485354\n",
      "Epoch 28/150 | Cost: 1.448664\n",
      "Epoch 29/150 | Cost: 1.412355\n",
      "Epoch 30/150 | Cost: 1.376543\n",
      "Epoch 31/150 | Cost: 1.341378\n",
      "Epoch 32/150 | Cost: 1.306948\n",
      "Epoch 33/150 | Cost: 1.273350\n",
      "Epoch 34/150 | Cost: 1.240627\n",
      "Epoch 35/150 | Cost: 1.208835\n",
      "Epoch 36/150 | Cost: 1.178057\n",
      "Epoch 37/150 | Cost: 1.148358\n",
      "Epoch 38/150 | Cost: 1.119727\n",
      "Epoch 39/150 | Cost: 1.092176\n",
      "Epoch 40/150 | Cost: 1.065706\n",
      "Epoch 41/150 | Cost: 1.040318\n",
      "Epoch 42/150 | Cost: 1.015992\n",
      "Epoch 43/150 | Cost: 0.992699\n",
      "Epoch 44/150 | Cost: 0.970417\n",
      "Epoch 45/150 | Cost: 0.949103\n",
      "Epoch 46/150 | Cost: 0.928734\n",
      "Epoch 47/150 | Cost: 0.909259\n",
      "Epoch 48/150 | Cost: 0.890648\n",
      "Epoch 49/150 | Cost: 0.872856\n",
      "Epoch 50/150 | Cost: 0.855851\n",
      "Epoch 51/150 | Cost: 0.839588\n",
      "Epoch 52/150 | Cost: 0.824028\n",
      "Epoch 53/150 | Cost: 0.809144\n",
      "Epoch 54/150 | Cost: 0.794890\n",
      "Epoch 55/150 | Cost: 0.781245\n",
      "Epoch 56/150 | Cost: 0.768178\n",
      "Epoch 57/150 | Cost: 0.755661\n",
      "Epoch 58/150 | Cost: 0.743672\n",
      "Epoch 59/150 | Cost: 0.732183\n",
      "Epoch 60/150 | Cost: 0.721165\n",
      "Epoch 61/150 | Cost: 0.710589\n",
      "Epoch 62/150 | Cost: 0.700437\n",
      "Epoch 63/150 | Cost: 0.690686\n",
      "Epoch 64/150 | Cost: 0.681309\n",
      "Epoch 65/150 | Cost: 0.672287\n",
      "Epoch 66/150 | Cost: 0.663599\n",
      "Epoch 67/150 | Cost: 0.655229\n",
      "Epoch 68/150 | Cost: 0.647169\n",
      "Epoch 69/150 | Cost: 0.639405\n",
      "Epoch 70/150 | Cost: 0.631919\n",
      "Epoch 71/150 | Cost: 0.624697\n",
      "Epoch 72/150 | Cost: 0.617730\n",
      "Epoch 73/150 | Cost: 0.611001\n",
      "Epoch 74/150 | Cost: 0.604497\n",
      "Epoch 75/150 | Cost: 0.598207\n",
      "Epoch 76/150 | Cost: 0.592123\n",
      "Epoch 77/150 | Cost: 0.586238\n",
      "Epoch 78/150 | Cost: 0.580539\n",
      "Epoch 79/150 | Cost: 0.575018\n",
      "Epoch 80/150 | Cost: 0.569668\n",
      "Epoch 81/150 | Cost: 0.564479\n",
      "Epoch 82/150 | Cost: 0.559445\n",
      "Epoch 83/150 | Cost: 0.554561\n",
      "Epoch 84/150 | Cost: 0.549816\n",
      "Epoch 85/150 | Cost: 0.545207\n",
      "Epoch 86/150 | Cost: 0.540729\n",
      "Epoch 87/150 | Cost: 0.536375\n",
      "Epoch 88/150 | Cost: 0.532139\n",
      "Epoch 89/150 | Cost: 0.528017\n",
      "Epoch 90/150 | Cost: 0.524004\n",
      "Epoch 91/150 | Cost: 0.520097\n",
      "Epoch 92/150 | Cost: 0.516292\n",
      "Epoch 93/150 | Cost: 0.512583\n",
      "Epoch 94/150 | Cost: 0.508968\n",
      "Epoch 95/150 | Cost: 0.505441\n",
      "Epoch 96/150 | Cost: 0.501999\n",
      "Epoch 97/150 | Cost: 0.498641\n",
      "Epoch 98/150 | Cost: 0.495363\n",
      "Epoch 99/150 | Cost: 0.492163\n",
      "Epoch 100/150 | Cost: 0.489036\n",
      "Epoch 101/150 | Cost: 0.485981\n",
      "Epoch 102/150 | Cost: 0.482996\n",
      "Epoch 103/150 | Cost: 0.480078\n",
      "Epoch 104/150 | Cost: 0.477224\n",
      "Epoch 105/150 | Cost: 0.474433\n",
      "Epoch 106/150 | Cost: 0.471701\n",
      "Epoch 107/150 | Cost: 0.469026\n",
      "Epoch 108/150 | Cost: 0.466408\n",
      "Epoch 109/150 | Cost: 0.463846\n",
      "Epoch 110/150 | Cost: 0.461338\n",
      "Epoch 111/150 | Cost: 0.458881\n",
      "Epoch 112/150 | Cost: 0.456473\n",
      "Epoch 113/150 | Cost: 0.454115\n",
      "Epoch 114/150 | Cost: 0.451803\n",
      "Epoch 115/150 | Cost: 0.449537\n",
      "Epoch 116/150 | Cost: 0.447314\n",
      "Epoch 117/150 | Cost: 0.445134\n",
      "Epoch 118/150 | Cost: 0.442996\n",
      "Epoch 119/150 | Cost: 0.440895\n",
      "Epoch 120/150 | Cost: 0.438834\n",
      "Epoch 121/150 | Cost: 0.436810\n",
      "Epoch 122/150 | Cost: 0.434823\n",
      "Epoch 123/150 | Cost: 0.432870\n",
      "Epoch 124/150 | Cost: 0.430952\n",
      "Epoch 125/150 | Cost: 0.429068\n",
      "Epoch 126/150 | Cost: 0.427216\n",
      "Epoch 127/150 | Cost: 0.425397\n",
      "Epoch 128/150 | Cost: 0.423607\n",
      "Epoch 129/150 | Cost: 0.421848\n",
      "Epoch 130/150 | Cost: 0.420119\n",
      "Epoch 131/150 | Cost: 0.418418\n",
      "Epoch 132/150 | Cost: 0.416743\n",
      "Epoch 133/150 | Cost: 0.415096\n",
      "Epoch 134/150 | Cost: 0.413474\n",
      "Epoch 135/150 | Cost: 0.411877\n",
      "Epoch 136/150 | Cost: 0.410306\n",
      "Epoch 137/150 | Cost: 0.408758\n",
      "Epoch 138/150 | Cost: 0.407235\n",
      "Epoch 139/150 | Cost: 0.405734\n",
      "Epoch 140/150 | Cost: 0.404256\n",
      "Epoch 141/150 | Cost: 0.402801\n",
      "Epoch 142/150 | Cost: 0.401367\n",
      "Epoch 143/150 | Cost: 0.399954\n",
      "Epoch 144/150 | Cost: 0.398560\n",
      "Epoch 145/150 | Cost: 0.397187\n",
      "Epoch 146/150 | Cost: 0.395832\n",
      "Epoch 147/150 | Cost: 0.394495\n",
      "Epoch 148/150 | Cost: 0.393176\n",
      "Epoch 149/150 | Cost: 0.391877\n",
      "Epoch 150/150 | Cost: 0.390595\n"
     ]
    }
   ],
   "source": [
    "learning_rate_alpha=0.05\n",
    "epochs=150\n",
    "for epoch in range(epochs):\n",
    "    Z1,Z2,Z3,Z4,A1,A2,A3,A4=forward_propagation(X_train,w1,b1,w2,b2,w3,b3,w4,b4)\n",
    "    dw1,dw2,dw3,dw4,db1,db2,db3,db4=back_propagation(X_train,Y_train,Z1,Z2,Z3,Z4,A1,A2,A3,A4,w1,b1,w2,b2,w3,b3,w4,b4)\n",
    "    cost=cost_function(Y_train,A4)\n",
    "    w1-=learning_rate_alpha*dw1\n",
    "    b1-=learning_rate_alpha*db1\n",
    "    w2-=learning_rate_alpha*dw2\n",
    "    b2-=learning_rate_alpha*db2\n",
    "    w3-=learning_rate_alpha*dw3\n",
    "    b3-=learning_rate_alpha*db3\n",
    "    w4-=learning_rate_alpha*dw4\n",
    "    b4-=learning_rate_alpha*db4\n",
    "    print(f\"Epoch {epoch+1}/{epochs} | Cost: {cost:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 769,
   "id": "45e5abaf-a976-489b-bdcc-226e5277f61f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 256) (784, 256)\n"
     ]
    }
   ],
   "source": [
    "print(dw1.shape,w1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 770,
   "id": "87f63711-71dc-4587-aa74-1dcfa42aacff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X,w1,b1,w2,b2,w3,b3,w4,b4):\n",
    "    Z1,Z2,Z3,Z4,A1,A2,A3,A4=forward_propagation(X,w1,b1,w2,b2,w3,b3,w4,b4)\n",
    "    return np.argmax(A4,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 771,
   "id": "29a546a5-c2f3-47fa-8628-98c1b6ed94f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(ytrue,ypred):\n",
    "    return np.mean(ytrue==ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 772,
   "id": "9e3eb909-0b17-41c3-9c2e-5534f1e1f0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_label=np.argmax(Y_train,axis=1)\n",
    "Y_cv_label=np.argmax(Y_cv,axis=1)\n",
    "Y_test_label=np.argmax(Y_test,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 773,
   "id": "f3f656ab-ef55-46b9-abc4-4f593f242496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.89272\n",
      "CV Accuracy: 0.9034\n",
      "Test Accuracy: 0.9001\n"
     ]
    }
   ],
   "source": [
    "train_preds = predict(X_train, w1, b1, w2, b2, w3, b3, w4, b4)\n",
    "cv_preds = predict(X_cv, w1, b1, w2, b2, w3, b3, w4, b4)\n",
    "test_preds = predict(X_test, w1, b1, w2, b2, w3, b3, w4, b4)\n",
    "\n",
    "print(\"Train Accuracy:\", accuracy(Y_train_label, train_preds))\n",
    "print(\"CV Accuracy:\", accuracy(Y_cv_label, cv_preds))\n",
    "print(\"Test Accuracy:\", accuracy(Y_test_label, test_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 774,
   "id": "07f592ff-dcd4-42e7-97d3-79cefb74ac7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 784) (10000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_cv.shape, cv_preds.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 804,
   "id": "ed8e4748-09df-4e03-b5db-3c77360322e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Got 10% accuracy on the projects prior debugging below is the debugging mechaanish I used\n",
    "# first looked at the cost function being stuck at 2.__ something then I finally changed my learning rates and tweaked random intialization parameters\n",
    "# Which came out to be a problem in my model and then I kept tweaking the parameters and reached 90% accuracy in this deeo neaural net build from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6310b225-4d97-4f3e-b820-42d32a1eaec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used minibatches too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 777,
   "id": "f4187a08-87ff-4ef2-bde3-3676dd372dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: cost = 0.15392873012388533\n",
      "Epoch 20: cost = 0.09040604338854824\n",
      "Epoch 30: cost = 0.06258339408076101\n",
      "Epoch 40: cost = 0.04742063260483258\n",
      "Epoch 50: cost = 0.03788817378737865\n",
      "Small batch accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "mini_X = X_train[:100]\n",
    "mini_Y = Y_train[:100]\n",
    "for epoch in range(50):\n",
    "    Z1, Z2, Z3, Z4, A1, A2, A3, A4 = forward_propagation(mini_X, w1, b1, w2, b2, w3, b3, w4, b4)\n",
    "    dw1, dw2, dw3, dw4, db1, db2, db3, db4 = back_propagation(mini_X, mini_Y, Z1, Z2, Z3, Z4, A1, A2, A3, A4, w1, b1, w2, b2, w3, b3, w4, b4)\n",
    "    cost = cost_function(mini_Y, A4)\n",
    "    w1 -= learning_rate_alpha * dw1\n",
    "    b1 -= learning_rate_alpha * db1\n",
    "    w2 -= learning_rate_alpha * dw2\n",
    "    b2 -= learning_rate_alpha * db2\n",
    "    w3 -= learning_rate_alpha * dw3\n",
    "    b3 -= learning_rate_alpha * db3\n",
    "    w4 -= learning_rate_alpha * dw4\n",
    "    b4 -= learning_rate_alpha * db4\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch + 1}: cost = {cost}\")        \n",
    "mini_preds = predict(mini_X, w1, b1, w2, b2, w3, b3, w4, b4)\n",
    "mini_labels = np.argmax(mini_Y, axis=1)\n",
    "print(\"Small batch accuracy:\", accuracy(mini_labels, mini_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 779,
   "id": "60ee142d-db6e-4816-8573-466daa82f387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Softmax A4 sample rows:\n",
      " [[2.96586272e-02 1.92085720e-03 6.86070640e-04 6.87549866e-02\n",
      "  2.74888855e-04 8.74652830e-01 1.42820870e-03 1.10756873e-03\n",
      "  1.50671757e-02 6.44878674e-03]\n",
      " [9.99320477e-01 8.64002757e-09 1.04292000e-05 2.12970485e-05\n",
      "  1.78605547e-06 5.82493810e-04 5.34117074e-06 1.92625348e-05\n",
      "  9.86194036e-06 2.90421656e-05]\n",
      " [3.58385376e-04 6.28990044e-05 6.12473922e-04 8.88455009e-04\n",
      "  9.68379072e-01 5.47127376e-04 1.90869534e-03 1.53727590e-03\n",
      "  7.32094326e-04 2.49735215e-02]\n",
      " [8.94247780e-06 9.83553473e-01 8.63300197e-04 1.00688740e-03\n",
      "  1.56714572e-04 1.23914163e-03 4.52531299e-04 1.24150815e-04\n",
      "  1.13831200e-02 1.21173841e-03]\n",
      " [4.69285451e-06 2.77394417e-05 2.81828801e-05 1.69067057e-05\n",
      "  5.48106783e-02 3.60657253e-05 4.61562213e-06 1.08641024e-02\n",
      "  4.54459928e-04 9.33752556e-01]]\n",
      "Row sums (should be 1): [1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "Z1, Z2, Z3, Z4, A1, A2, A3, A4 = forward_propagation(X_train[:5], w1, b1, w2, b2, w3, b3, w4, b4)\n",
    "print(\"Softmax A4 sample rows:\\n\", A4)\n",
    "print(\"Row sums (should be 1):\", np.sum(A4, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 791,
   "id": "73081929-04ea-47dd-a2a3-fd11586abfb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dw1 mean/std/min/max :  -4.7782391411507776e-05 0.001843626474197183 -0.018842272015883985 0.01962688030435938\n",
      "dw2 mean/std/min/max :  9.32895901918468e-06 0.003941163346121476 -0.04153144347684647 0.04191941658277587\n",
      "dw3 mean/std/min/max :  0.00012142878327400087 0.007376070934735101 -0.06428436075933437 0.05554932488311138\n",
      "dw4 mean/std/min/max :  5.893994060174323e-18 0.02267276793404715 -0.152484346829236 0.08566791045512626\n"
     ]
    }
   ],
   "source": [
    "X_dbg = X_train[:4]\n",
    "Y_dbg = Y_train[:4]\n",
    "Z1, Z2, Z3, Z4, A1, A2, A3, A4 = forward_propagation(X_dbg, w1, b1, w2, b2, w3, b3, w4, b4)\n",
    "dw1, dw2, dw3, dw4, db1, db2, db3, db4 = back_propagation(X_dbg, Y_dbg, Z1, Z2, Z3, Z4, A1, A2, A3, A4, w1, b1, w2, b2, w3, b3, w4, b4)\n",
    "print(\"dw1 mean/std/min/max : \", np.mean(dw1), np.std(dw1), np.min(dw1), np.max(dw1))\n",
    "print(\"dw2 mean/std/min/max : \", np.mean(dw2), np.std(dw2), np.min(dw2), np.max(dw2))\n",
    "print(\"dw3 mean/std/min/max : \", np.mean(dw3), np.std(dw3), np.min(dw3), np.max(dw3))\n",
    "print(\"dw4 mean/std/min/max : \", np.mean(dw4), np.std(dw4), np.min(dw4), np.max(dw4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 824,
   "id": "0b83d3f0-9824-4ac0-a1bb-c17107ed0eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 838,
   "id": "eb77ec42-d8ee-4501-87a9-24534c5c86c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def visualization(X, preds, trueValue, index=0):\n",
    "    plt.imshow(X[index].reshape(28, 28), cmap='gray')\n",
    "    plt.title(f\"Predicted: {preds[index]}, True Label: {trueValue[index]}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "visualization(X_test, test_preds, Y_test_label, index=9999) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884a0b7d-69b0-4074-bdf5-358b92cfaeac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
